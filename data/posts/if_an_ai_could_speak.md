---
title: if_an_ai_could_speak
date: 2023-09-07 14:57:05.922839 UTC
description: 'The power of language, statistics and just how far we still are from something meaningful coming from ai'
draft: false
---

## Whereof one cannot speak

Like everyone else I've been thinking a lot about AI, LLMs, and the like. I've always been fascinated with the idea that if AGI comes 
how will we really tell and when do they become a person with rights? This isn't a new 21st Centurary thought. The 1920 play _R.U.R._ asks when a 
robot reaches AGI, what's the difference between a human's soul and freedom, and a robot's? Examining that question eventually brings us back 
to Plato and souls, and Wittgenstein's idea of the unsayable.

I'll posit two _beliefs_:
- **To believe AGI is possible is to deny the existence of free will.**
- **If an AI could speak we would not understand it.**

The idea that silicon and electricity can become self aware and conscious means there's nothing more to consciousness. There's nothing magic. There's [no God](https://r00ks.io/bl0g/to_the_ships,_philosophers!) in a sense.
Sure there's quantum randomness, but our thoughts are just that random. We're nothing more.

Stepping back from that Nilishitic path, what's incredible and factual in this moment is an LLM's ability to appear life-like with just statistical
analysis of words. We don't really think of language on a quotodian level of being a powerful system, but that's exactly what it is. And 
for humanists and writers that's an incredibly obvious statement, but it's taken for granted because we use it everyday. 

And yet when think about consciousness and what feels to be alive, what it feels to feel something--language doesn't feel like enough.

> The truth is you already know what it’s like. You already know
> the difference between the size and speed of everything that flashes
> through you and the tiny inadequate bit of it all you can ever let anyone know. 
> As though inside you is this enormous room full of what
> seems like everything in the whole universe at one time or another and
> yet the only parts that get out have to somehow squeeze out through
> one of those tiny keyholes you see under the knob in older doors. As if
> we are all trying to see each other through these tiny keyholes.
>
> -- <cite>David Foster Wallace, Good Old Neon</cite>

Language just gets us through the keyhole. There's an unsayable mystery to life and consciousness.

Modeling language gets us a chat bot that is creative and intelligent. It's able to respond within the context of the conversation.
That's incredible all by itself.

If you didn't have language would you still have consciousness?

Is Chat GPT more intelligent than a fly? Is it more conscious?

If a Chat GPT model of a dog's consciousness be created what would it be like?

What's not so clear to the population at large, is what I believe to be the looming limit of LLMs. What's very clear is these are
already valuable as is and ever more gradual improvements will still be worthwhile tasks. People seem to completely disregard the history
of every major step in AI - it's always been one huge innovation with massive investment followed by a come to realization that we're
much futher away than we thought. 

So are LLMs overhyped? Yes in their potential; no in their worth. 

From Hofstader:

> I frankly am baffled by the allure, for so many unquestionably insightful people (including many friends of mine), of letting opaque computational systems perform intellectual tasks for them. Of course it makes sense to let a computer do obviously mechanical tasks, such as computations, but
> when it comes to using language in a sensitive manner and talking about real-life situations where the distinction between truth and falsity and between genuineness and fakeness is absolutely crucial, to me it makes no sense whatsoever to let the artificial voice of a chatbot, chatting randomly away at dazzling speed, replace the far slower but authentic and reflective voice of a thinking, living human being.
>
> To fall for the illusion that vast computational systems “who” have never had a single experience in the real world outside of text are nevertheless perfectly reliable authorities about the world at large is a deep mistake, and, if that mistake is repeated sufficiently often and comes to be widely accepted, it will undermine the very nature of truth on which our society—and I mean all of human society—is based.
>
> --<cite>Douglas Hofstader</cite>

